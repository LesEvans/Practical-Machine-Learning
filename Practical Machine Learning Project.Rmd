---
title: Pratical Machine Learning Project
output: html_document
---

##Synoposis
This project used the data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. These participants were asked to perform barbell lifts correctly and incorrectly in 5 different ways. According to Velloso et al 2013 Class A the the appopriate application of the exercise, while Class B, C, D and E are common errors in the preformance of the exercise.  

Using 4 predictive models, it was discovered that Random Forest and Gradient Boosting can use the data generated by the accelerometers to predict whether the barbell lifts were performed correctly.  If the lift was performed incorrectly, the prediction model allowed the realisation which of the common errors occured.  

It may be possible to use and appropriate prediction model and accelerometers to provide feedback to participants who perform barbell lifts while unsupervised either at a gym or at home.

##Data Processing

The dataset was downloaded from *https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv* while the training set was downloaded from *https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv*.

To set this project up, I will be using the following packages.
```{r}
library(AppliedPredictiveModeling)
library(caret)
library(rattle)
library(rpart.plot)
library(randomForest)
```
The training and test data are loaded using the following code.
```{r}
Data<-read.csv("pml-training.csv",na.strings=c("NA",""), header=TRUE)
Test<-read.csv("pml-testing.csv",na.strings=c("NA",""), header=TRUE)
a<-dim(Data)
```
The data set is large with dimensions [`r a`]. Initial inspection of the Data set suggests that many of the columns do not contain much data which is evident in the form of NAs or white space.  These columns will be removed.
```{r}
NAs <- function(x) {
  as.vector(apply(x, 2, function(x) length(which(is.na(x)))))
}
col<-NAs(Data)
col
```

**Table One**  The count of missing values in each column of the Data set.

All columns with more than 19000 missing values will be removed.
```{r}
col_names<-colnames(Data)
d<-data.frame(col_names,col)
miss<-subset(d,col==19216)
newdata<-Data[,!(names(Data) %in% miss$col_names)]
```
Further the first seven columns are do not contain data collected from the accelerometers so will also be removed
```{r}
newdata<-newdata[,-c(1:7)]
b<-dim(newdata)
```
Under this data cleansing, the dimesions of the training set are now [`r b`].

##Pre-Processing of the Data
In the first instance, any variables with a near zero variance need to be identified and removed
```{r}
nzv <- nearZeroVar(newdata, saveMetrics = TRUE)
```
Using Near Zero Variance test, it was discovered that all columns had enough variance to remain part of the predictive model.

In the second instance highly correlated variables will be identified and removed.  Any column with a correlation greater than 0.9 will be removed. 
```{r}
cor <- cor(newdata[,-53])

h_Cor <- findCorrelation(cor, cutoff = 0.9)
newdata2<-newdata[,-h_Cor]
c<-length(h_Cor)
d<-dim(newdata2)
```
Under these circumstances, I found `r c` columns were highly correlated.  These were removed which gave a data set of dimensions of [`r d`] that can be used to construct a predictive model.

The final test will be for linear dependence, any columns which are linearly dependent will be removed.
```{r}
Lin_Dep <- findLinearCombos(newdata2[,-46])
Lin_Dep
```
When this test was conducted, it was found that all columns were linearly independent.  As a consequence, I will use **newdata2** to build a predictive model.  

Given the size of the dataset, it is possible to explore a number of predictive models, which will allow the comparison and the building of accuracy.  For this reason data set (newdata2) will be partitioned into four randomly selected subgroups of approximately equal size.

##Data Splitting
```{r}
set.seed(1704)
train_sets <- createDataPartition(newdata2$classe, p = .5,list = FALSE,times = 2)
set1<-newdata2[train_sets[,1],]
set2<-newdata2[-train_sets[,1],]
set3<-newdata2[train_sets[,2],]
set4<-newdata2[-train_sets[,2],]
```


I believe that given that the action of the participants when lifting a barbell will either be correct or incorrect in one of four ways a classification tree would be an appropriate methodology for creating a prediction model.     

The intention is to build four predictive models each based on classification trees.  The first model that will be considered will be simple classification tree using recursive partitioning and regression trees.

##Predictive Model 1 -- Using rpart
```{r}
set.seed(1704)
training <- createDataPartition(set1$classe, p = .8,list = FALSE)
Train1<-set1[training,]
Test1<-set1[-training,]
Fit1 <- train(Train1$classe ~ ., method="rpart", data=Train1)
pred1 <- predict(Fit1, newdata=Test1)
con_mat1<-confusionMatrix(pred1, Test1$classe)
Acc1<-as.numeric(con_mat1$overall[1]*100)
CIl1<-as.numeric(con_mat1$overall[3]*100)
CIu1<-as.numeric(con_mat1$overall[4]*100)
Err1<-100-Acc1
rpart<- predict(Fit1, newdata=Test)
```
Using recursive partitioning (refer Appendix One) the best predictive model has a accuracy of 58%.  The Out of Sample accuracy was `r Acc1`% which suggests an out of sample error of `r Err1`%.  This is a poor result so another predictive model needs to be considered.

##Predictive Model 2 -- Ctree
A second recursive partitioning model is ctree which is a conditional inference tree which takes into account the distributional properties of the variables.  This process should lead to a stronger predictive model.
```{r}
training2 <- createDataPartition(set2$classe, p = .8,list = FALSE)
Train2<-set2[training,]
Test2<-set2[-training,]
Fit2 <- train(Train2$classe ~ ., method="ctree", data=Train2)
pred2 <- predict(Fit2, newdata=Test2)
con_ctree<-confusionMatrix(pred2, Test2$classe)
ctree<- predict(Fit2, newdata=Test)
Acc2<-as.numeric(con_ctree$overall[1]*100)
CIl2<-as.numeric(con_ctree$overall[3]*100)
CIu2<-as.numeric(con_ctree$overall[4]*100)
Err2<-100-Acc2
```
Using a conditional inference tree (refer Appendix Two) best predictive model has a accuracy of 82%.  The Out of Sample accuracy was `r Acc2`% which suggests an out of sample error of `r Err2`%.  While this is a strong improvement, it is worth exploring alternatives that may offer greater predictive power.

Given that Ctree produces a single tree with relatively strong results, it may be possible to combine several trees to create a better predictive model.  This could be achieved by using boosting.

##Predictive Model 3 -- Gradient Boosting (GBM)
Gradient boosting models generates a prediction models by using a collection of weaker classification trees which act together.  In a sense it can use the models in the form of the previous trees which act together.  For this reason GBM may create better predictive models.
```{r}
training <- createDataPartition(set3$classe, p = .8,list = FALSE)
Train3<-set3[training,]
Test3<-set3[-training,]
gbmFit <- train(classe~., data = Train3,method = "gbm",verbose = F)
pred3 <- predict(gbmFit, newdata=Test3)
gbmFit_conf<-confusionMatrix(pred3, Test3$classe)
GBM<-(predict(gbmFit, newdata=Test))
Acc3<-as.numeric(gbmFit_conf$overall[1]*100)
CIl3<-as.numeric(gbmFit_conf$overall[3]*100)
CIu3<-as.numeric(gbmFit_conf$overall[4]*100)
Err3<-100-Acc3
```
Using a Gradient Boosting (refer Appendix Three) the best predictive model has an accuracy of 94.5%.  The Out of Sample accuracy was `r Acc3`% which suggests an out of sample error of `r Err3`%.  This is a very strong improvement, and it is interesting that the test data set produced a better result than the training set. 

##Predictive Model 4 -- Random Forest
Random forests uses a collection of decision trees which are all used in the predictive process, the prediction is based on the mode of the results produced by individual trees. I believe that it could produce a similar or stronger predictive result than the previous models.  Given that Predictive Models 3 and 4 use a collection of Decision Trees it is likely they will produce similar results.

```{r}
training <- createDataPartition(set4$classe, p = .8,list = FALSE)
Train4<-set4[training,]
Test4<-set4[-training,]
RFT <- train(Train4$classe ~ ., method="rf", data=Train4)
pred4 <- predict(RFT, newdata=Test4)
con_rf<-confusionMatrix(pred4, Test4$classe)
RF<-(predict(RFT, newdata=Test))
Acc4<-as.numeric(con_rf$overall[1]*100)
CIl4<-as.numeric(con_rf$overall[3]*100)
CIu4<-as.numeric(con_rf$overall[4]*100)
Err4<-100-Acc4
```
Using a Random Forest (refer Appendix Four) the best predictive model has a accuracy of 98.1%.  The Out of Sample accuracy was `r Acc4`% which suggests an out of sample error of `r Err4`.  Given the level of accuracy In and Out of Sample, this would be an appropriate model to use to predict the result on the Test data set.  

##Summary
###
When each of the models were used to predict the outcomes for the provided Test Dataset, the following results were obtained.  Given the level of accuracy of the Gradient Boost and Random forest models and consistency with the predictions, these will be used for the submission part of this assignment.  Thankfully, when tested this decision was appropriate given that the results were authenticated when submitted.

```{r}
Summary<-data.frame(rpart,ctree,GBM,RF)
print(Summary)
```

###Model Accuracy
Each model was built using the **train** function in the carat package.  In each case Cross validation was achieved using bootstrapping. The results for each Model was:
Rpart 58%
Ctree 82%
GBM 94.6%
Random Forest 98.1%

###Cross Validation and out-of-Sample Prediction Accuracy Estimates

*Rpart* *Accuracy* `r Acc1`% with *95% Confidence Interval* [`r CIl1`,`r CIu1`] and an *out of sample error* of `r Err1`%

*Ctree* *Accuracy* `r Acc2`% with *95% Confidence Interval* [`r CIl2`,`r CIu2`] and an *out of sample error* of `r Err2`%

*GBM* *Accuracy* `r Acc3`% with *95% Confidence Interval* [`r CIl3`,`r CIu3`] and an *out of sample error* of `r Err3`%

*Random Forest* *Accuracy* `r Acc4`% with *95% Confidence Interval* [`r CIl4`,`r CIu4`] and an *out of sample error* of `r Err4`%

#Appendix One
##Predictive Model 1 -- Using rpart
### The Predictive Model
```{r}
print(Fit1, digits=3)
```
###Confusion Matrix 
```{r}
print((con_mat1),digits = 3)
```
###rpart Predictions on the Test Data Set
```{r}
print(rpart)
```
#Appendix Two
##Predictive Model 2 -- Using ctree
### The Predictive Model
```{r}
print(Fit2, digits=3)
```
###Confusion Matrix 
```{r}
print((con_ctree),digits = 3)
```
###Ctree Predictions on the Test Data Set
```{r}
print(ctree)
```
#Appendix Three
##Predictive Model 3 -- Gradient Boosted Model
### The Predictive Model
```{r}
print(gbmFit, digits=3)
```
###Confusion Matrix 
```{r}
print((gbmFit_conf),digits = 3)
```
###GBM Predictions on the Test Data Set
```{r}
print((GBM),digits=3)
```

#Appendix Four
##Predictive Model 4 -- Random Forest
### The Predictive Model
```{r}
print(RFT, digits=3)
```
###Confusion Matrix 
```{r}
print((con_rf),digits = 3)
```
###GBM Predictions on the Test Data Set
```{r}
print((RF),digits=3)
```
#Bibliography
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.


